{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a25144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmudipalli\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7ca375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3b0e6",
   "metadata": {},
   "source": [
    "## Overall topics in most helpful and least helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5519be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Topics from 'Most Helpful' ---\n",
      "Topic #0: 0.021*\"like\" + 0.016*\"activity\" + 0.016*\"team\" + 0.016*\"find\" + 0.016*\"well\" + 0.011*\"student\" + 0.011*\"set\" + 0.011*\"allow\" + 0.011*\"class\" + 0.011*\"coverage\"\n",
      "Topic #1: 0.055*\"helpful\" + 0.027*\"study\" + 0.022*\"session\" + 0.018*\"help\" + 0.017*\"find\" + 0.016*\"strategy\" + 0.013*\"tour\" + 0.013*\"different\" + 0.013*\"allow\" + 0.013*\"campus\"\n",
      "Topic #2: 0.027*\"study\" + 0.026*\"feel\" + 0.020*\"helpful\" + 0.020*\"know\" + 0.018*\"plan\" + 0.018*\"different\" + 0.018*\"enjoy\" + 0.014*\"like\" + 0.013*\"find\" + 0.013*\"activity\"\n",
      "Topic #3: 0.020*\"know\" + 0.018*\"think\" + 0.018*\"help\" + 0.014*\"helpful\" + 0.012*\"class\" + 0.012*\"schedule\" + 0.012*\"have\" + 0.012*\"problem\" + 0.012*\"day\" + 0.012*\"software\"\n",
      "Topic #4: 0.027*\"help\" + 0.026*\"helpful\" + 0.023*\"know\" + 0.020*\"feel\" + 0.019*\"student\" + 0.016*\"time\" + 0.016*\"faculty\" + 0.016*\"presentation\" + 0.016*\"like\" + 0.014*\"start\"\n",
      "\n",
      "Coherence Score: 0.301\n",
      "\n",
      "--- Topics from 'Least Helpful' ---\n",
      "Topic #0: 0.027*\"software\" + 0.027*\"class\" + 0.022*\"download\" + 0.022*\"follow\" + 0.022*\"little\" + 0.018*\"lecture\" + 0.017*\"helpful\" + 0.017*\"demo\" + 0.017*\"maybe\" + 0.017*\"tutorial\"\n",
      "Topic #1: 0.033*\"break\" + 0.033*\"schedule\" + 0.028*\"presentation\" + 0.024*\"time\" + 0.022*\"think\" + 0.020*\"long\" + 0.020*\"little\" + 0.020*\"helpful\" + 0.020*\"feel\" + 0.020*\"study\"\n",
      "Topic #2: 0.034*\"day\" + 0.031*\"feel\" + 0.027*\"helpful\" + 0.026*\"find\" + 0.022*\"useful\" + 0.018*\"orientation\" + 0.018*\"presentation\" + 0.014*\"part\" + 0.014*\"think\" + 0.009*\"like\"\n",
      "Topic #3: 0.028*\"download\" + 0.022*\"presentation\" + 0.022*\"follow\" + 0.020*\"think\" + 0.019*\"software\" + 0.019*\"use\" + 0.014*\"time\" + 0.013*\"helpful\" + 0.013*\"information\" + 0.013*\"difficult\"\n",
      "Topic #4: 0.037*\"helpful\" + 0.023*\"feel\" + 0.023*\"set\" + 0.019*\"study\" + 0.017*\"like\" + 0.014*\"presentation\" + 0.014*\"paper\" + 0.014*\"find\" + 0.014*\"plan\" + 0.014*\"calendar\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmudipalli\\AppData\\Local\\anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "C:\\Users\\hmudipalli\\AppData\\Local\\anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: nan\n"
     ]
    }
   ],
   "source": [
    "# Load your CSV file\n",
    "df = pd.read_excel(\"Orientation Evaluation Data_2025.xlsx\", usecols=[10,12,13,18])\n",
    "\n",
    "# Focus on the two open-ended questions\n",
    "most_helpful = df.iloc[:, 1].dropna().astype(str).tolist()\n",
    "least_helpful = df.iloc[:, 2].dropna().astype(str).tolist()\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(texts):\n",
    "    processed_texts = []\n",
    "    for doc in nlp.pipe(texts, batch_size=500):\n",
    "        tokens = [token.lemma_.lower() for token in doc \n",
    "                  if token.is_alpha and not token.is_stop and len(token) > 2]\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts\n",
    "\n",
    "# Preprocess text\n",
    "most_helpful_clean = preprocess(most_helpful)\n",
    "least_helpful_clean = preprocess(least_helpful)\n",
    "\n",
    "# Create dictionary and corpus\n",
    "def create_lda_model(clean_texts, num_topics=5):\n",
    "    dictionary = corpora.Dictionary(clean_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in clean_texts]\n",
    "\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=num_topics,\n",
    "                         random_state=42,\n",
    "                         update_every=1,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=True)\n",
    "    \n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "# Create and show topics\n",
    "def display_topics(lda_model, dictionary, corpus):\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"Topic #{idx}: {topic}\")\n",
    "\n",
    "    # Coherence score (optional)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=most_helpful_clean,\n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "    print(f\"\\nCoherence Score: {coherence_model.get_coherence():.3f}\")\n",
    "\n",
    "# Model on 'Most Helpful'\n",
    "print(\"\\n--- Topics from 'Most Helpful' ---\")\n",
    "lda_most, corpus_most, dict_most = create_lda_model(most_helpful_clean)\n",
    "display_topics(lda_most, dict_most, corpus_most)\n",
    "\n",
    "# Model on 'Least Helpful'\n",
    "print(\"\\n--- Topics from 'Least Helpful' ---\")\n",
    "lda_least, corpus_least, dict_least = create_lda_model(least_helpful_clean)\n",
    "display_topics(lda_least, dict_least, corpus_least)\n",
    "\n",
    "# Optional: Visualize with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f958e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize with pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "vis = gensimvis.prepare(lda_most, corpus_most, dict_most)\n",
    "pyLDAvis.save_html(vis, 'lda_most_helpful.html') #pyLDAvis.show(vis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796bd522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis = gensimvis.prepare(lda_least, corpus_least, dict_least)\n",
    "pyLDAvis.save_html(vis, 'lda_least_helpful.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992d53b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['How would you rate your overall experience with Orientation Week? (Numerical Answer)',\n",
       "       'Which part of orientation did you find most helpful and why?',\n",
       "       'Which part of orientation did you find least helpful and why?',\n",
       "       'What changes or improvements would you suggest for Orientation Week and why?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20ded60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 📊 Rating: 2 ===\n",
      "\n",
      "🔹 Topics for: Feedback (Rating 2)\n",
      "  Topic #0: 0.038*\"try\" + 0.038*\"download\" + 0.038*\"time\" + 0.021*\"uncomfortable\" + 0.021*\"make\" + 0.021*\"lot\" + 0.021*\"idea\" + 0.021*\"difficult\" + 0.021*\"period\" + 0.021*\"get\"\n",
      "  Topic #1: 0.022*\"download\" + 0.022*\"time\" + 0.022*\"try\" + 0.022*\"long\" + 0.022*\"people\" + 0.022*\"consideration\" + 0.022*\"virtual\" + 0.022*\"bonding\" + 0.022*\"option\" + 0.022*\"multiple\"\n",
      "  Topic #2: 0.022*\"time\" + 0.022*\"try\" + 0.022*\"download\" + 0.022*\"sunlight\" + 0.022*\"consideration\" + 0.022*\"info\" + 0.022*\"uneven\" + 0.022*\"lighting\" + 0.022*\"session\" + 0.022*\"hour\"\n",
      "  Topic #3: 0.022*\"time\" + 0.022*\"try\" + 0.022*\"feel\" + 0.022*\"lighting\" + 0.022*\"download\" + 0.022*\"consideration\" + 0.022*\"question\" + 0.022*\"food\" + 0.022*\"lot\" + 0.022*\"hour\"\n",
      "  Topic #4: 0.022*\"download\" + 0.022*\"time\" + 0.022*\"virtual\" + 0.022*\"suggest\" + 0.022*\"try\" + 0.022*\"team\" + 0.022*\"consideration\" + 0.022*\"campus\" + 0.022*\"answering\" + 0.022*\"room\"\n",
      "  Coherence Score: 1.000\n",
      "\n",
      "=== 📊 Rating: 3 ===\n",
      "\n",
      "🔹 Topics for: Feedback (Rating 3)\n",
      "  Topic #0: 0.032*\"group\" + 0.032*\"long\" + 0.032*\"need\" + 0.022*\"time\" + 0.022*\"small\" + 0.012*\"think\" + 0.012*\"maybe\" + 0.012*\"activity\" + 0.012*\"lot\" + 0.012*\"new\"\n",
      "  Topic #1: 0.032*\"know\" + 0.025*\"bit\" + 0.025*\"interaction\" + 0.024*\"opportunity\" + 0.022*\"time\" + 0.017*\"like\" + 0.017*\"get\" + 0.017*\"start\" + 0.017*\"lot\" + 0.017*\"think\"\n",
      "  Topic #2: 0.023*\"student\" + 0.023*\"day\" + 0.023*\"group\" + 0.023*\"suggest\" + 0.016*\"break\" + 0.016*\"people\" + 0.016*\"time\" + 0.016*\"software\" + 0.016*\"possible\" + 0.016*\"clear\"\n",
      "  Topic #3: 0.032*\"people\" + 0.026*\"break\" + 0.026*\"like\" + 0.020*\"presentation\" + 0.020*\"activity\" + 0.020*\"nice\" + 0.020*\"long\" + 0.020*\"maybe\" + 0.014*\"friend\" + 0.014*\"building\"\n",
      "  Topic #4: 0.054*\"day\" + 0.040*\"activity\" + 0.027*\"time\" + 0.026*\"break\" + 0.026*\"presentation\" + 0.021*\"long\" + 0.021*\"like\" + 0.021*\"team\" + 0.016*\"orientation\" + 0.012*\"student\"\n",
      "  Coherence Score: 0.317\n",
      "\n",
      "=== 📊 Rating: 4 ===\n",
      "\n",
      "🔹 Topics for: Feedback (Rating 4)\n",
      "  Topic #0: 0.045*\"opportunity\" + 0.034*\"group\" + 0.034*\"roadrunner_group\" + 0.024*\"class\" + 0.024*\"small\" + 0.024*\"member\" + 0.024*\"feel\" + 0.013*\"improvement\" + 0.013*\"orientation\" + 0.013*\"like\"\n",
      "  Topic #1: 0.031*\"time\" + 0.016*\"tech\" + 0.016*\"presentation\" + 0.016*\"issue\" + 0.016*\"ahead\" + 0.016*\"set\" + 0.016*\"feel\" + 0.016*\"student\" + 0.016*\"improvement\" + 0.016*\"well\"\n",
      "  Topic #2: 0.055*\"day\" + 0.034*\"activity\" + 0.026*\"think\" + 0.022*\"feel\" + 0.022*\"early\" + 0.018*\"short\" + 0.018*\"break\" + 0.017*\"start\" + 0.017*\"bit\" + 0.013*\"know\"\n",
      "  Topic #3: 0.027*\"thursday\" + 0.019*\"session\" + 0.019*\"outside\" + 0.019*\"little\" + 0.019*\"presentation\" + 0.019*\"plan\" + 0.019*\"day\" + 0.010*\"help\" + 0.010*\"able\" + 0.010*\"have\"\n",
      "  Topic #4: 0.024*\"orientation\" + 0.024*\"download\" + 0.018*\"day\" + 0.018*\"time\" + 0.018*\"have\" + 0.018*\"like\" + 0.012*\"improvement\" + 0.012*\"feel\" + 0.012*\"provide\" + 0.012*\"prior\"\n",
      "  Coherence Score: 0.485\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_excel(\"Orientation Evaluation Data_2025.xlsx\", usecols=[10, 18])\n",
    "df.columns = ['Ratings', 'Feedback']  # Rename for clarity\n",
    "\n",
    "# Drop NaNs in relevant columns\n",
    "df = df.dropna(subset=['Ratings'])\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(texts):\n",
    "    processed_texts = []\n",
    "    for doc in nlp.pipe(texts, batch_size=500):\n",
    "        tokens = [token.lemma_.lower() for token in doc \n",
    "                  if token.is_alpha and not token.is_stop and len(token) > 2]\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts\n",
    "\n",
    "# Step 2: Build Bigrams/Trigrams\n",
    "def add_phrases(docs, min_count=2, threshold=5):\n",
    "    bigram = Phrases(docs, min_count=min_count, threshold=threshold)\n",
    "    bigram_mod = Phraser(bigram)\n",
    "    \n",
    "    trigram = Phrases(bigram_mod[docs], threshold=threshold)\n",
    "    trigram_mod = Phraser(trigram)\n",
    "\n",
    "    # Apply bigram and trigram models\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in docs]\n",
    "\n",
    "# Function to create and display topic model\n",
    "def create_and_display_lda(texts, label, num_topics=5):\n",
    "    clean_texts = preprocess(texts)\n",
    "    # Add bigrams/trigrams\n",
    "    phrased_docs = add_phrases(clean_texts)\n",
    "    dictionary = corpora.Dictionary(phrased_docs)\n",
    "    corpus = [dictionary.doc2bow(text) for text in phrased_docs]\n",
    "\n",
    "    if len(dictionary) == 0:\n",
    "        print(f\"⚠️ Skipping '{label}' – not enough content after preprocessing.\")\n",
    "        return\n",
    "\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=num_topics,\n",
    "                         random_state=42,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=False)\n",
    "\n",
    "    print(f\"\\n🔹 Topics for: {label}\")\n",
    "    for idx, topic in lda_model.print_topics(-1):\n",
    "        print(f\"  Topic #{idx}: {topic}\")\n",
    "    \n",
    "    # Coherence Score\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=phrased_docs, #clean_texts\n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "    print(f\"  Coherence Score: {coherence_model.get_coherence():.3f}\")\n",
    "    \n",
    "    return lda_model, dictionary, corpus\n",
    "\n",
    "# Group by Ratings and run topic modeling\n",
    "for rating_value, group in df.groupby('Ratings'):\n",
    "    print(f\"\\n=== 📊 Rating: {rating_value} ===\")\n",
    "\n",
    "    # Most Helpful\n",
    "    feedback_texts = group['Feedback'].dropna().astype(str).tolist()\n",
    "    if feedback_texts:\n",
    "        lda_model, dictionary, corpus = create_and_display_lda(feedback_texts, f\"Feedback (Rating {rating_value})\")\n",
    "    \n",
    "    ## visual html\n",
    "    vis_feedback = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis_feedback, f'lda_feedback_rating_{rating_value}.html')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab024917",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_feedback = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis_feedback, 'lda_feedback.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4908e313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.045*\"opportunity\" + 0.034*\"group\" + 0.034*\"roadrunner_group\" + 0.024*\"class\" + 0.024*\"small\" + 0.024*\"member\" + 0.024*\"feel\" + 0.013*\"improvement\" + 0.013*\"orientation\" + 0.013*\"like\"'),\n",
       " (1,\n",
       "  '0.031*\"time\" + 0.016*\"tech\" + 0.016*\"presentation\" + 0.016*\"issue\" + 0.016*\"ahead\" + 0.016*\"set\" + 0.016*\"feel\" + 0.016*\"student\" + 0.016*\"improvement\" + 0.016*\"well\"'),\n",
       " (2,\n",
       "  '0.055*\"day\" + 0.034*\"activity\" + 0.026*\"think\" + 0.022*\"feel\" + 0.022*\"early\" + 0.018*\"short\" + 0.018*\"break\" + 0.017*\"start\" + 0.017*\"bit\" + 0.013*\"know\"'),\n",
       " (3,\n",
       "  '0.027*\"thursday\" + 0.019*\"session\" + 0.019*\"outside\" + 0.019*\"little\" + 0.019*\"presentation\" + 0.019*\"plan\" + 0.019*\"day\" + 0.010*\"help\" + 0.010*\"able\" + 0.010*\"have\"'),\n",
       " (4,\n",
       "  '0.024*\"orientation\" + 0.024*\"download\" + 0.018*\"day\" + 0.018*\"time\" + 0.018*\"have\" + 0.018*\"like\" + 0.012*\"improvement\" + 0.012*\"feel\" + 0.012*\"provide\" + 0.012*\"prior\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
